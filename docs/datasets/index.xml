<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datasets on GTDLBench</title>
    <link>/GTDLBench/datasets/</link>
    <description>Recent content in Datasets on GTDLBench</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="/GTDLBench/datasets/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MNIST</title>
      <link>/GTDLBench/datasets/mnist_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/mnist_datasets/</guid>
      <description>MNIST Dataset The MNIST database of handwritten digits&#xA;Download Raw Dataset&#xA;Dataset Statistics Color: Grey-scale Sample Size: 28x28 The number of categories of MNIST is 10, that is 0-9, 10 digits.&#xA;The Number of Samples per Category for MNIST Category 0 1 2 3 4 5 6 7 8 9 Total #Training Samples 5,923 6,742 5,958 6,131 5,842 5,421 5,918 6,265 5,851 5,949 60,000 #Testing Samples 980 1,135 1,032 1,010 982 892 958 1,028 974 1,009 10,000 Samples Dataset Usage MNIST in CSV The format is:</description>
    </item>
    <item>
      <title>CIFAR-10</title>
      <link>/GTDLBench/datasets/cifar-10_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/cifar-10_datasets/</guid>
      <description>CIFAR-10 dataset The CIFAR-10 dataset&#xA;Dataset Statistics Color: RGB Sample Size: 32x32 The number of categories of CIFAR-10 is 10, that is airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.&#xA;The Number of Samples per Category for CIFAR-10 Category airplane automobile bird cat deer dog frog horse ship truck Total #Training Samples 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 50,000 #Testing Samples 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 10,000 Samples Dataset Usage TensorFlow: TensorFlow @TensorFlow_Convolutional_Neural_Networks</description>
    </item>
    <item>
      <title>CIFAR-100</title>
      <link>/GTDLBench/datasets/cifar-100_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/cifar-100_datasets/</guid>
      <description>CIFAR-100 dataset The CIFAR-100 dataset&#xA;Dataset Statistics Color: RGB Sample Size: 32x32 This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are roughly grouped into 20 superclasses. Each image comes with a &amp;ldquo;fine&amp;rdquo; label (the class to which it belongs) and a &amp;ldquo;coarse&amp;rdquo; label (the superclass to which it belongs).</description>
    </item>
    <item>
      <title>Faces (AT&amp;T)</title>
      <link>/GTDLBench/datasets/att_face_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/att_face_dataset/</guid>
      <description>The Database of Faces (AT&amp;amp;T) The Database of Faces&#xA;Dataset Statistics Color: Grey-scale Sample Size: 92x112 #Samples: 400 Dataset Size: 4.5 MB (compressed in .tar.z) The original files are in PGM format, and can conveniently be viewed on UNIX (TM) systems using the &amp;lsquo;xv&amp;rsquo; program. The size of each image is 92x112 pixels, with 256 grey levels per pixel. The images are organised in 40 directories (one for each subject), which have names of the form sX, where X indicates the subject number (between 1 and 40).</description>
    </item>
    <item>
      <title>CALTECH101</title>
      <link>/GTDLBench/datasets/caltech101_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/caltech101_datasets/</guid>
      <description>CALTECH101 The CALTECH101 dataset&#xA;Caltech-101 contains a total of 9,146 images, split between 101 distinct object categories (faces, watches, ants, pianos, etc.) and a background category. This dataset contains 102 folders, the BACKGROUND_Google (the background category) can be removed, and users may use the left 101 categoies.&#xA;Dataset Statistics Color: RGB Sample size: Roughtly 300x200 Dataset size: 1.2 GB Overall, the dataset consists of pictures of objects belonging to 101 categories.</description>
    </item>
    <item>
      <title>CALTECH256</title>
      <link>/GTDLBench/datasets/caltech256_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/caltech256_datasets/</guid>
      <description>CALTECH256 The CALTECH256 dataset&#xA;Dataset Statistics Color: RGB Sample Size: Camprison with Caltech-101: The Number of Samples per Category for Caltech-256 Samples Dataset Usage TensorFlow: Git clone https://github.com/yukunchen113/ResnetCNN.git cd RestNetCNN Use caltech256_bin.py to convet caltech256 images to tfrecord files for faster reading. Use caltech256_input.py input functions to convert input iput functions to batch images and labels. Model.py contains resnet model. Train.py trains the model Evals.py evaluates the model. Caffe: Git clone https://github.</description>
    </item>
    <item>
      <title>ImageNet</title>
      <link>/GTDLBench/datasets/imagenet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/imagenet/</guid>
      <description>IMAGENET The IMAGENET dataset&#xA;ImageNet is a dataset of images that are organized according to the WordNet hierarchy. WordNet contains approximately 100,000 phrases and ImageNet has provided around 1000 images on average to illustrate each phrase.&#xA;Dataset Statistics Size 150 GB Number of Records: Total number of images: ~1,500,000; each with multiple bounding boxes and respective class labels&#xA;* Total number of non-empty synsets: 21841 * Total number of images: 14,197,122 * Number of images with bounding box annotations: 1,034,908 * Number of synsets with SIFT features: 1000 * Number of images with SIFT features: 1.</description>
    </item>
    <item>
      <title>LISA Traffic Sign</title>
      <link>/GTDLBench/datasets/lisa_traffic_sign_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/lisa_traffic_sign_dataset/</guid>
      <description>LISA Traffic Sign Dataset The LISA_Traffic_Sign Dataset&#xA;The LISA Traffic Sign Dataset is a set of videos and annotated frames containing US traffic signs. It is released in two stages, one with only the pictures and one with both pictures and videos. The images are available now, while the full dataset is underway and will be made available soon.&#xA;Dataset Statistics 47 US sign types 7855 annotations on 6610 frames. Sign sizes from 6x6 to 167x168 pixels.</description>
    </item>
    <item>
      <title>USPS Dataset</title>
      <link>/GTDLBench/datasets/usps_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/usps_dataset/</guid>
      <description>USPS Dataset A database for handwritten text recognition research.&#xA;Download Raw Dataset USPS Dataset&#xA;USPS Testing Dataset&#xA;Dataset Statistics # of classes: 10 # of data: 7291 / 2007 (testing) # of features: 256 Samples Dataset Usage TensorFlow: https://github.com/darshanbagul/USPS_Digit_Classification&#xA;USPS_Digit_Classification Requirements tensorflow==1.0.1&#xD;matplotlib==1.5.1&#xD;cv2==2.4.13&#xD;numpy==1.13.0&#xD;cPickle==1.71 Implementation 1. Logistic Regression&#xD;2. Single layered Neural Networks&#xD;3. Convolutional Neural Networks&#xD;Results Logistic Regression&#xA;Accuracy on USPS data - 36.30 %&#xA;Single Layer Neural Network</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/audioset_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/audioset_dataset/</guid>
      <description>AudioSet The AudioSet dataset&#xA;The AudioSet dataset is a large-scale collection of human-labeled 10-second sound clips drawn from YouTube videos. There are 2,084,320 YouTube videos containing 527 labels.&#xA;Dataset Statistics Reference paper https://research.google.com/pubs/pub45857.html&#xA;Samples Dataset Usage Info about Dataset AudioSet dataset for download in two formats:&#xA;Text (csv) files describing, for each segment, the YouTube video ID, start time, end time, and one or more labels.&#xA;128-dimensional audio features extracted at 1Hz.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/celeba_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/celeba_dataset/</guid>
      <description>Large-scale CelebFaces Attributes (CelebA) Dataset The CelebA dataset&#xA;CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter. CelebA has large diversities, large quantities, and rich annotations. The dataset can be employed as the training and test sets for the following computer vision tasks: face attribute recognition, face detection, and landmark (or facial part) localization.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/coil100_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/coil100_datasets/</guid>
      <description>Columbia Object Image Library (COIL-100) The COIL-100 dataset&#xA;This is a database of gray-scale images of 100 objects. The objects were placed on a motorized turntable against a black background. The turntable was rotated through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. The images were size normalized.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/coil20/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/coil20/</guid>
      <description>Columbia Object Image Library (COIL-20) The COIL20 dataset&#xA;This is a database of gray-scale images of 20 objects. The objects were placed on motorized turntable.The turn table was rotated through 360 degrees to vary object pose with respect to fixed camera.Images of objects were taken at pose interval of 5 degrees.This corresponds to 72 images per object.&#xA;Dataset Statistics The database has two sets. The first set contains 720 unprocessed images of 10 objects.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/kinetics_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/kinetics_datasets/</guid>
      <description>Kinetics The Kinetics dataset&#xA;Kinetics is a large-scale, high-quality dataset of YouTube video URLs which include a diverse range of human focused actions&#xA;Statistics The dataset consists of approximately 300,000 video clips, and covers 400 human action classes with at least 400 video clips for each action class. Each clip lasts around 10s and is labeled with a single class. All of the clips have been through multiple rounds of human annotation, and each is taken from a unique YouTube video.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/labelme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/labelme/</guid>
      <description>Labelme Labelme Train in Spain and test in the rest of the world dataset&#xA;Try to recognize and segment as many object categories as you can. Training images correspond to outdoor pictures taken in different cities of Spain.&#xA;Dataset Statistics Training set: contains more than 1000 fully annotated images and around 2000 partially annotated images. Including partially annotated images allows algorithms to show if they are able to benefit from additional partially labeled images.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/norb_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/norb_dataset/</guid>
      <description>NORB DATASET The Norb dataset&#xA;This database is intended for experiments in 3D object reocgnition from shape. It contains images of 50 toys belonging to 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. The objects were imaged by two cameras under 6 lighting conditions, 9 elevations (30 to 70 degrees every 5 degrees), and 18 azimuths (0 to 340 every 20 degrees)&#xA;Dataset Statistics The training set is composed of 5 instances of each category (instances 4, 6, 7, 8 and 9), and the test set of the remaining 5 instances (instances 0, 1, 2, 3, and 5).</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/openimages/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/openimages/</guid>
      <description>Open Images Dataset The Open Images dataset Open Images is a dataset of almost 9 million URLs for images. These images have been annotated with image-level labels bounding boxes spanning thousands of classes. The dataset contains a training set of 9,011,219 images, a validation set of 41,260 images and a test set of 125,436 images.&#xA;Dataset Statistics Size 500 GB (Compressed) Number of Records: 9,011,219 images with more than 5k labels References Imagenet Samples Dataset Usage git clone https://github.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/stl10_datset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/stl10_datset/</guid>
      <description>STL10 The STL-10 dataset&#xA;The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the CIFAR-10 dataset but with some modifications. In particular, each class has fewer labeled training examples than in CIFAR-10, but a very large set of unlabeled examples is provided to learn image models prior to supervised training.&#xA;Dataset Statistics 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.</description>
    </item>
    <item>
      <title></title>
      <link>/GTDLBench/datasets/vqa_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/GTDLBench/datasets/vqa_datasets/</guid>
      <description>VISUAL QA The VQA dataset&#xA;VQA is a new dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer.&#xA;Dataset Statistics 265,016 images (COCO and abstract scenes) 1,105,904 questions 11,059,040 ground truth answers&#xA;At least 3 questions (5.4 questions on average) per image 10 ground truth answers per question 3 plausible (but likely incorrect) answers per question Automatic evaluation metric&#xA;References VQA: Visual Question Answering Samples Dataset Usage Download dataset http://www.</description>
    </item>
  </channel>
</rss>
