<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GTDLBench</title>
    <link>/GTDLBench/</link>
    <description>Recent content on GTDLBench</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/GTDLBench/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MNIST</title>
      <link>/GTDLBench/comparison/tutorials/benchmarking_on_mnist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/comparison/tutorials/benchmarking_on_mnist/</guid>
      <description>Benchmarking on MNIST: The following mentioned model definition files are under the folder: models/mnist/ .
Pre-setting: DLBENCH_ROOT=&amp;quot;path to the root directory of this benchmark&amp;quot;  TensorFlow: TensorFlow uses a variant of LeNet and its network structure is shown as follows:   TensorFlow default model   Run TensorFlow with its default MNIST setting:
cd $DLBENCH_ROOT/models/mnist/tensorflow/ python mnist_deep.py  The Training Time, Testing Time and Accuracy will appear after completion.</description>
    </item>
    
    <item>
      <title>CIFAR-10</title>
      <link>/GTDLBench/comparison/tutorials/benchmarking_on_cifar10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/comparison/tutorials/benchmarking_on_cifar10/</guid>
      <description>Benchmarking on CIFAR-10: The following mentioned model definition files are under the folder: models/cifar10/ .
Pre-setting: DLBENCH_ROOT=&amp;quot;path to the root directory of this benchmark&amp;quot;  TensorFlow: Run TensorFlow with its default MNIST setting:
cd $DLBENCH_ROOT/models/cifar10/tensorflow/ python cifar10_train.py &amp;gt; train_log.txt 2&amp;gt;&amp;amp;1  After the completion of training, run the following command to test the tranined model:
python cifar10_eval.py &amp;gt; test_log.txt 2&amp;gt;&amp;amp;1  The Accuracy will appear after completion of cifar10_eval.py. And the Training Time and Testing Time can be extracted from the train_log.</description>
    </item>
    
    <item>
      <title>CIFAR-100</title>
      <link>/GTDLBench/comparison/tutorials/benchmarking_on_cifar100/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/comparison/tutorials/benchmarking_on_cifar100/</guid>
      <description>Benchmarking on CIFAR-100: The following mentioned model definition files are under the folder: models/cifar100/ .
Pre-setting: DLBENCH_ROOT=&amp;quot;path to the root directory of this benchmark&amp;quot;  TensorFlow: Run TensorFlow with its default MNIST setting:
cd $DLBENCH_ROOT/models/cifar100/tensorflow/ python cifar100_train.py &amp;gt; train_log.txt 2&amp;gt;&amp;amp;1  After the completion of training, run the following command to test the tranined model:
python cifar100_eval.py &amp;gt; test_log.txt 2&amp;gt;&amp;amp;1  The Accuracy will appear after completion of cifar100_eval.py. And the Training Time and Testing Time can be extracted from the train_log.</description>
    </item>
    
    <item>
      <title>MNIST</title>
      <link>/GTDLBench/datasets/mnist_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/mnist_datasets/</guid>
      <description>MNIST Dataset The MNIST database of handwritten digits
Download Raw Dataset
Dataset Statistics  Color: Grey-scale Sample Size: 28x28  The number of categories of MNIST is 10, that is 0-9, 10 digits.
The Number of Samples per Category for MNIST    Category 0 1 2 3 4 5 6 7 8 9 Total     #Training Samples 5,923 6,742 5,958 6,131 5,842 5,421 5,918 6,265 5,851 5,949 60,000   #Testing Samples 980 1,135 1,032 1,010 982 892 958 1,028 974 1,009 10,000    Samples Dataset Usage MNIST in CSV The format is:</description>
    </item>
    
    <item>
      <title>CIFAR-10</title>
      <link>/GTDLBench/datasets/cifar-10_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/cifar-10_datasets/</guid>
      <description>CIFAR-10 dataset The CIFAR-10 dataset
Dataset Statistics  Color: RGB Sample Size: 32x32  The number of categories of CIFAR-10 is 10, that is airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.
The Number of Samples per Category for CIFAR-10    Category airplane automobile bird cat deer dog frog horse ship truck Total     #Training Samples 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 5,000 50,000    #Testing Samples 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 1,000 10,000    Samples Dataset Usage TensorFlow: TensorFlow @TensorFlow_Convolutional_Neural_Networks</description>
    </item>
    
    <item>
      <title>Comparison on MNIST</title>
      <link>/GTDLBench/comparison/mnist_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/comparison/mnist_comparison/</guid>
      <description>The benchmarking results are as following figure shows:
      google.charts.load(&#39;visualization&#39;, &#39;1&#39;, {&#39;package&#39;:[&#39;corechart&#39;, &#39;controls&#39;]}); function drawChart() { $.get(&#34;\/GTDLBench\/data\/MNISTServer1.csv&#34;, function(csvString) { var tmpData = $.csv.toArrays(csvString, {onParseValue: $.csv.hooks.castToScala}); var arrayData = []; var arrayData1 = []; var arrayData2 = []; for (var i = 0; i  </description>
    </item>
    
    <item>
      <title>CIFAR-100</title>
      <link>/GTDLBench/datasets/cifar-100_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/cifar-100_datasets/</guid>
      <description>CIFAR-100 dataset The CIFAR-100 dataset
Dataset Statistics  Color: RGB Sample Size: 32x32  This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are roughly grouped into 20 superclasses. Each image comes with a &amp;ldquo;fine&amp;rdquo; label (the class to which it belongs) and a &amp;ldquo;coarse&amp;rdquo; label (the superclass to which it belongs).</description>
    </item>
    
    <item>
      <title>Comparison on CIFAR-10</title>
      <link>/GTDLBench/comparison/cifar10_comparison/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/comparison/cifar10_comparison/</guid>
      <description>The benchmarking results are as following figure shows:
      google.charts.load(&#39;visualization&#39;, &#39;1&#39;, {&#39;package&#39;:[&#39;corechart&#39;, &#39;controls&#39;]}); function drawChart() { $.get(&#34;\/GTDLBench\/data\/CIFAR10Server1.csv&#34;, function(csvString) { var tmpData = $.csv.toArrays(csvString, {onParseValue: $.csv.hooks.castToScala}); var arrayData = []; var arrayData1 = []; var arrayData2 = []; for (var i = 0; i  </description>
    </item>
    
    <item>
      <title>Faces (AT&amp;T)</title>
      <link>/GTDLBench/datasets/att_face_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/att_face_dataset/</guid>
      <description>The Database of Faces (AT&amp;amp;T) The Database of Faces
Dataset Statistics  Color: Grey-scale Sample Size: 92x112 #Samples: 400 Dataset Size: 4.5 MB (compressed in .tar.z)  The original files are in PGM format, and can conveniently be viewed on UNIX &amp;trade; systems using the &amp;lsquo;xv&amp;rsquo; program. The size of each image is 92x112 pixels, with 256 grey levels per pixel. The images are organised in 40 directories (one for each subject), which have names of the form sX, where X indicates the subject number (between 1 and 40).</description>
    </item>
    
    <item>
      <title>CALTECH101</title>
      <link>/GTDLBench/datasets/caltech101_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/caltech101_datasets/</guid>
      <description>CALTECH101 The CALTECH101 dataset
Caltech-101 contains a total of 9,146 images, split between 101 distinct object categories (faces, watches, ants, pianos, etc.) and a background category. This dataset contains 102 folders, the BACKGROUND_Google (the background category) can be removed, and users may use the left 101 categoies.
Dataset Statistics  Color: RGB Sample size: Roughtly 300x200 Dataset size: 1.2 GB  Overall, the dataset consists of pictures of objects belonging to 101 categories.</description>
    </item>
    
    <item>
      <title>CALTECH256</title>
      <link>/GTDLBench/datasets/caltech256_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/caltech256_datasets/</guid>
      <description>CALTECH256 The CALTECH256 dataset
Dataset Statistics  Color: RGB Sample Size:  Camprison with Caltech-101: The Number of Samples per Category for Caltech-256 Samples Dataset Usage TensorFlow: Git clone https://github.com/yukunchen113/ResnetCNN.git cd RestNetCNN   Use caltech256_bin.py to convet caltech256 images to tfrecord files for faster reading. Use caltech256_input.py input functions to convert input iput functions to batch images and labels. Model.py contains resnet model. Train.py trains the model Evals.py evaluates the model.</description>
    </item>
    
    <item>
      <title>ImageNet</title>
      <link>/GTDLBench/datasets/imagenet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/imagenet/</guid>
      <description>IMAGENET The IMAGENET dataset
ImageNet is a dataset of images that are organized according to the WordNet hierarchy. WordNet contains approximately 100,000 phrases and ImageNet has provided around 1000 images on average to illustrate each phrase.
Dataset Statistics Size 150 GB Number of Records: Total number of images: ~1,500,000; each with multiple bounding boxes and respective class labels
* Total number of non-empty synsets: 21841 * Total number of images: 14,197,122 * Number of images with bounding box annotations: 1,034,908 * Number of synsets with SIFT features: 1000 * Number of images with SIFT features: 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/_footer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/_footer/</guid>
      <description> &amp;copy; Georgia Institute of Technology </description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/audioset_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/audioset_dataset/</guid>
      <description>AudioSet The AudioSet dataset
The AudioSet dataset is a large-scale collection of human-labeled 10-second sound clips drawn from YouTube videos. There are 2,084,320 YouTube videos containing 527 labels.
Dataset Statistics Reference paper https://research.google.com/pubs/pub45857.html
Samples Dataset Usage Info about Dataset AudioSet dataset for download in two formats:
Text (csv) files describing, for each segment, the YouTube video ID, start time, end time, and one or more labels.
128-dimensional audio features extracted at 1Hz.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/celeba_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/celeba_dataset/</guid>
      <description>Large-scale CelebFaces Attributes (CelebA) Dataset The CelebA dataset
CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter. CelebA has large diversities, large quantities, and rich annotations. The dataset can be employed as the training and test sets for the following computer vision tasks: face attribute recognition, face detection, and landmark (or facial part) localization.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/kinetics_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/kinetics_datasets/</guid>
      <description>Kinetics The Kinetics dataset
Kinetics is a large-scale, high-quality dataset of YouTube video URLs which include a diverse range of human focused actions
Statistics The dataset consists of approximately 300,000 video clips, and covers 400 human action classes with at least 400 video clips for each action class. Each clip lasts around 10s and is labeled with a single class. All of the clips have been through multiple rounds of human annotation, and each is taken from a unique YouTube video.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/lisa_traffic_sign_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/lisa_traffic_sign_dataset/</guid>
      <description>LISA Traffic Sign Dataset The LISA_Traffic_Sign Dataset
The LISA Traffic Sign Dataset is a set of videos and annotated frames containing US traffic signs. It is released in two stages, one with only the pictures and one with both pictures and videos. The images are available now, while the full dataset is underway and will be made available soon.
Dataset Statistics  47 US sign types 7855 annotations on 6610 frames.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/vqa_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/vqa_datasets/</guid>
      <description>VISUAL QA The VQA dataset
VQA is a new dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer.
Dataset Statistics 265,016 images (COCO and abstract scenes) 1,105,904 questions 11,059,040 ground truth answers
At least 3 questions (5.4 questions on average) per image 10 ground truth answers per question 3 plausible (but likely incorrect) answers per question Automatic evaluation metric</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/coil100_datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/coil100_datasets/</guid>
      <description>Columbia Object Image Library (COIL-100) The COIL-100 dataset
This is a database of gray-scale images of 100 objects. The objects were placed on a motorized turntable against a black background. The turntable was rotated through 360 degrees to vary object pose with respect to a fixed color camera. Images of the objects were taken at pose intervals of 5 degrees. This corresponds to 72 poses per object. The images were size normalized.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/coil20/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/coil20/</guid>
      <description>Columbia Object Image Library (COIL-20) The COIL20 dataset
This is a database of gray-scale images of 20 objects. The objects were placed on motorized turntable.The turn table was rotated through 360 degrees to vary object pose with respect to fixed camera.Images of objects were taken at pose interval of 5 degrees.This corresponds to 72 images per object.
Dataset Statistics The database has two sets. The first set contains 720 unprocessed images of 10 objects.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/labelme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/labelme/</guid>
      <description>Labelme Labelme Train in Spain and test in the rest of the world dataset
Try to recognize and segment as many object categories as you can. Training images correspond to outdoor pictures taken in different cities of Spain.
Dataset Statistics Training set: contains more than 1000 fully annotated images and around 2000 partially annotated images. Including partially annotated images allows algorithms to show if they are able to benefit from additional partially labeled images.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/norb_dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/norb_dataset/</guid>
      <description>NORB DATASET The Norb dataset
This database is intended for experiments in 3D object reocgnition from shape. It contains images of 50 toys belonging to 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. The objects were imaged by two cameras under 6 lighting conditions, 9 elevations (30 to 70 degrees every 5 degrees), and 18 azimuths (0 to 340 every 20 degrees)
Dataset Statistics The training set is composed of 5 instances of each category (instances 4, 6, 7, 8 and 9), and the test set of the remaining 5 instances (instances 0, 1, 2, 3, and 5).</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/openimages/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/openimages/</guid>
      <description>Open Images Dataset The Open Images dataset Open Images is a dataset of almost 9 million URLs for images. These images have been annotated with image-level labels bounding boxes spanning thousands of classes. The dataset contains a training set of 9,011,219 images, a validation set of 41,260 images and a test set of 125,436 images.
Dataset Statistics Size 500 GB (Compressed) Number of Records: 9,011,219 images with more than 5k labels References  Imagenet  Samples Dataset Usage git clone https://github.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/datasets/stl10_datset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/datasets/stl10_datset/</guid>
      <description>STL10 The STL-10 dataset
The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the CIFAR-10 dataset but with some modifications. In particular, each class has fewer labeled training examples than in CIFAR-10, but a very large set of unlabeled examples is provided to learn image models prior to supervised training.
Dataset Statistics 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/frameworks/caffe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/frameworks/caffe/</guid>
      <description> Caffe The statistical info of Caffe is shown as follows:
 678 text files. 677 unique files.
 282 files ignored.  CLOC v 1.60 T=2.68 s (162.6 files/s, 36000.4 lines/s)    Language files blank comment code     C++ 188 4726 4888 41803   C/C++ Header 106 3341 7438 18325   Python 38 1431 3026 5232   CMake 33 435 476 1957   MATLAB 22 94 205 627   Bourne Shell 40 166 159 589   make 1 92 107 500   CSS 3 71 8 359   HTML 2 19 8 173   YAML 2 11 20 43   SUM: 435 10386 16335 69608    </description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/frameworks/mxnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/frameworks/mxnet/</guid>
      <description>2116 text files.
2088 unique files.
705 files ignored.
cloc v 1.60 T=4.60 s (317.1 files/s, 71521.2 lines/s)
   Language files blank comment code     Python 563 16447 35338 70836   C/C++ Header 258 6874 16657 58866   C++ 193 5318 6582 35875   Perl 79 3874 4689 21408   Scala 130 2683 5911 15865   Bourne Shell 107 820 2274 3014   Java 41 609 954 2175   Maven 17 67 13 1535   CMake 14 270 378 1489   CSS 1 237 47 1192   Javascript 10 121 168 1165   make 10 179 199 772   MATLAB 6 116 326 724   Cython 6 105 118 591   HTML 4 26 18 359   DOS Batch 4 85 81 270   YAML 8 51 60 261   C 1 20 28 201   XML 4 32 32 192   Bourne Again Shell 1 7 21 19   SUM: 1457 37941 73894 216809    </description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/frameworks/tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/frameworks/tensorflow/</guid>
      <description>LOC 0.4.1
   Language Files Lines Blank Comment Code     Python 2309 729862 109417 65993 554452   C++ 2581 696781 90510 80917 525354   C/C++ Header 1372 209403 33251 57547 118605   Markdown 263 47881 10571 0 37310   Go 29 31742 1882 14027 15833   Java 85 16319 2209 3948 10162   Bourne Shell 112 11554 1595 3440 6519   Protobuf 94 9206 1463 3686 4057   Plain Text 41 3716 251 0 3465   Objective-C++ 18 2709 389 321 1999   C 9 1320 169 141 1010   Makefile 10 1407 178 266 963   XML 45 1429 253 445 731   Batch 10 276 57 0 219   Perl 2 227 36 41 150   JSON 4 126 0 0 126    LinkerScript 8 64 4 0 60   Objective-C 2 88 20 26 42   YAML 1 42 3 24 15   Autoconf 1 13 0 0 13   Total 6996 1764165 252258 230822 1281085    </description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/frameworks/theano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/frameworks/theano/</guid>
      <description>LOC
Language Files Lines Blank Comment Code Python 380 216122 34663 18566 162893 Plain Text 189 35241 9147 0 26094 C 51 26012 1903 5110 18999 TeX 4 3317 415 286 2616 JavaScript 10 2044 220 296 1528 HTML 4 404 32 0 372 CUDA 2 451 59 100 292 CUDA Header 1 433 84 75 274 CSS 4 254 40 0 214 C/C++ Header 5 141 25 25 91 YAML 1 66 6 0 60 reStructuredText 1 50 15 0 35 Batch 1 43 8 0 35 Makefile 3 35 9 3 23 Autoconf 1 15 0 0 15 Bourne Shell 1 21 4 2 15</description>
    </item>
    
    <item>
      <title></title>
      <link>/GTDLBench/frameworks/torch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/GTDLBench/frameworks/torch/</guid>
      <description>166 text files. 166 unique files.
66 files ignored.
[CLOC]()http://cloc.sourceforge.net) v 1.60 T=0.86 s (159.7 files/s, 41829.2 lines/s)
   Language files blank comment code     C 50 2668 955 17270   Lua 21 1227 424 8701   C/C++ Header 51 465 281 2287   CMake 14 197 186 1409   YAML 2 0 0 83    </description>
    </item>
    
  </channel>
</rss>